{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEFS Wave Global Collection\n",
    "\n",
    "Reads the Global GEFS Wave grib collection from NODD's S3 bucket and creates a single dataset using fsspec's ReferenceFileSystem\n",
    "\n",
    "This notebook demonstrates how to generate the reference JSON files using Kerchunk and gribberish. It was adapted from [this notebook](https://nbviewer.org/gist/peterm790/92eb1df3d58ba41d3411f8a840be2452)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the virtual filesystem from which to read the NODD s3 bucket. We are going to write the resulting dataset out to our local filesystem, so we leave the write system blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_read = fsspec.filesystem('s3', anon=True, skip_instance_cache=True, use_ssl=False) # For now SSL false is solving my cert issues **shrug**\n",
    "fs_write = fsspec.filesystem('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, grab all of the files for the given model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 105 GEFS files\n"
     ]
    }
   ],
   "source": [
    "#https://noaa-gefs-pds.s3.amazonaws.com/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f012.grib2\n",
    "gefs_ens_member_files = fs_read.glob('s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.*.grib2')\n",
    "\n",
    "files = sorted(['s3://'+f for f in gefs_ens_member_files])\n",
    "print(f'Read {len(files)} GEFS files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file, we will scan it with gribberish and extract its data to a dictionary formatted to the zarr spec. Then we will write that dictionary to a JSON file with the name formatting specified in the `make_json_name` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "from gribberish.kerchunk import scan_gribberish\n",
    "\n",
    "so = {\"anon\": True, \"use_ssl\": False}\n",
    "json_dir = 'gefs_wave/'\n",
    "\n",
    "def make_json_name(file_url, message_number): #create a unique name for each reference file\n",
    "    date = file_url.split('/')[3].split('.')[1]\n",
    "    name = file_url.split('/')[7].split('.')[0:7]\n",
    "    return f'{json_dir}{date}_{name[0]}_{name[1]}_{name[2]}_{name[4]}_{name[3]}_{name[6]}_message{message_number}.json'\n",
    "\n",
    "def gen_json(file_url):\n",
    "    out = scan_gribberish(file_url, storage_options=so, only_vars=['htsgw'], skip=1) \n",
    "    for i, message in enumerate(out):\n",
    "        print(f'Writing message {i} from {file_url}')\n",
    "        out_file_name = make_json_name(file_url, i)  # get name\n",
    "        with fs_write.open(out_file_name, \"w\") as f: \n",
    "            f.write(ujson.dumps(message)) # write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f000.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f003.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f006.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f009.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f012.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f015.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f018.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f021.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f024.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f027.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f030.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f033.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f036.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f039.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f042.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f045.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f048.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f051.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f054.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f057.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f060.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f063.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f066.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f069.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f072.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f075.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f078.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f081.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f084.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f087.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f090.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f093.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f096.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f099.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f102.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f105.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f108.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f111.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f114.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f117.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f120.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f123.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f126.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f129.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f132.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f135.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f138.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f141.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f144.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f147.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f150.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f153.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f156.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f159.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f162.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f165.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f168.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f171.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f174.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f177.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f180.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f183.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f186.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f189.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f192.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f195.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f198.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f201.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f204.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f207.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f210.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f213.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f216.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f219.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f222.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f225.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f228.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f231.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f234.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f237.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f240.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f246.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f252.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f258.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f264.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f270.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f276.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f282.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f288.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f294.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f300.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f306.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f312.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f318.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f324.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f330.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f336.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f342.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f348.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f354.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f360.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f366.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f372.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f378.grib2...\n",
      "Processing s3://noaa-gefs-pds/gefs.20230706/12/wave/gridded/gefs.wave.t12z.p01.global.0p25.f384.grib2...\n",
      "CPU times: user 2.69 s, sys: 3.15 s, total: 5.85 s\n",
      "Wall time: 37.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#this step is best run via a cluster\n",
    "for f in files:\n",
    "    gen_json(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once generated, it can be read back in with xarray or zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "type",
     "evalue": "[Errno 2] No such file or directory: '/Users/matthewiannucci/Developer/gribberish/python/examples/gefs_wave/20230706_gefs_wave_t12z_global_p01_f000_message0.json/.zmetadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxarray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# open dataset as zarr object using fsspec reference file system and xarray\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m fs \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39;49mfilesystem(\u001b[39m\"\u001b[39;49m\u001b[39mreference\u001b[39;49m\u001b[39m\"\u001b[39;49m, fo\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./gefs_wave/20230706_gefs_wave_t12z_global_p01_f000_message0.json\u001b[39;49m\u001b[39m'\u001b[39;49m, remote_protocol\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms3\u001b[39;49m\u001b[39m'\u001b[39;49m, remote_options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39manon\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39muse_ssl\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m})\n\u001b[1;32m      5\u001b[0m m \u001b[39m=\u001b[39m fs\u001b[39m.\u001b[39mget_mapper(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m ds \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(m, engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzarr\u001b[39m\u001b[39m\"\u001b[39m, backend_kwargs\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(consolidated\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/registry.py:267\u001b[0m, in \u001b[0;36mfilesystem\u001b[0;34m(protocol, **storage_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39marrow_hdfs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m protocol has been deprecated and will be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mremoved in the future. Specify it as \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhdfs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    263\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m get_filesystem_class(protocol)\n\u001b[0;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/spec.py:79\u001b[0m, in \u001b[0;36m_Cached.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache[token]\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m     \u001b[39m# Setting _fs_token here causes some static linters to complain.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     obj\u001b[39m.\u001b[39m_fs_token_ \u001b[39m=\u001b[39m token\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/implementations/reference.py:606\u001b[0m, in \u001b[0;36mReferenceFileSystem.__init__\u001b[0;34m(self, fo, target, ref_storage_args, target_protocol, target_options, remote_protocol, remote_options, fs, template_overrides, simple_templates, max_gap, max_block, cache_size, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m         \u001b[39m# Lazy parquet refs\u001b[39;00m\n\u001b[1;32m    605\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mOpen lazy reference dict from URL \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, fo)\n\u001b[0;32m--> 606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreferences \u001b[39m=\u001b[39m LazyReferenceMapper(\n\u001b[1;32m    607\u001b[0m             fo2,\n\u001b[1;32m    608\u001b[0m             fs\u001b[39m=\u001b[39;49mref_fs,\n\u001b[1;32m    609\u001b[0m             cache_size\u001b[39m=\u001b[39;49mcache_size,\n\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     \u001b[39m# dictionaries\u001b[39;00m\n\u001b[1;32m    613\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_references(fo, template_overrides)\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/implementations/reference.py:120\u001b[0m, in \u001b[0;36mLazyReferenceMapper.__init__\u001b[0;34m(self, root, fs, out_root, cache_size, categorical_threshold)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39mfilesystem(\u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m fs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m fs\n\u001b[0;32m--> 120\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, \u001b[39m\"\u001b[39;49m\u001b[39m.zmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m]), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items[\u001b[39m\"\u001b[39m\u001b[39m.zmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m    122\u001b[0m met \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items[\u001b[39m\"\u001b[39m\u001b[39m.zmetadata\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/spec.py:1241\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1240\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1241\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1242\u001b[0m         path,\n\u001b[1;32m   1243\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1244\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1245\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1246\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1247\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1248\u001b[0m     )\n\u001b[1;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/implementations/local.py:184\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/implementations/local.py:315\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    314\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 315\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/Developer/gribberish/python/examples/env/lib/python3.9/site-packages/fsspec/implementations/local.py:320\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 320\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    321\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    322\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/matthewiannucci/Developer/gribberish/python/examples/gefs_wave/20230706_gefs_wave_t12z_global_p01_f000_message0.json/.zmetadata'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# open dataset as zarr object using fsspec reference file system and xarray\n",
    "fs = fsspec.filesystem(\"reference\", fo='./gefs_wave/20230706_gefs_wave_t12z_global_p01_f000_message0.json', remote_protocol='s3', remote_options={'anon':True, 'use_ssl': False})\n",
    "m = fs.get_mapper(\"\")\n",
    "ds = xr.open_dataset(m, engine=\"zarr\", backend_kwargs=dict(consolidated=False))\n",
    "ds         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.htsgw.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a single dataset from the collection of the kerchunked files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerchunk.combine import MultiZarrToZarr\n",
    "import numpy as np\n",
    "\n",
    "reference_jsons = fs_write.ls(json_dir) #get list of file names\n",
    "\n",
    "def fn_to_ens(index, fs, var, fn):\n",
    "    import re\n",
    "    import datetime\n",
    "    groups = re.search(r\"\\_p(\\d{2})\", fn).groups()\n",
    "    return int(groups[0])\n",
    "\n",
    "# combine individual references into single consolidated reference\n",
    "mzz = MultiZarrToZarr(reference_jsons,\n",
    "                        coo_map={'ens': fn_to_ens},\n",
    "                        coo_dtypes={'ens': np.dtype('int32')},\n",
    "                        concat_dims = ['ens', 'time'],\n",
    "                        identical_dims=['latitude', 'longitude'])\n",
    "d = mzz.translate()\n",
    "\n",
    "with open('./gefs_wave/gefswave_kerchunk.json', 'w') as f:\n",
    "    f.write(ujson.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset as zarr object using fsspec reference file system and xarray\n",
    "fs = fsspec.filesystem(\"reference\", fo='./gefs_wave/gefswave_kerchunk.json', remote_protocol='s3', remote_options={'anon':True, 'use_ssl': False})\n",
    "m = fs.get_mapper(\"\")\n",
    "ds = xr.open_dataset(m, engine=\"zarr\", backend_kwargs=dict(consolidated=False), \n",
    "                      chunks={'time':1})\n",
    "\n",
    "ds                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
